/**
 * Run production migration via direct database connection
 * Usage: DATABASE_URL="postgresql://..." node scripts/run-production-migration.js
 */

require('dotenv').config();

// Override knex config to use production DATABASE_URL
const knex = require('knex')({
  client: 'postgresql',
  connection: process.env.DATABASE_URL || process.env.PRODUCTION_DATABASE_URL,
  pool: {
    min: 1,
    max: 5
  },
  migrations: {
    directory: './database/migrations',
    tableName: 'knex_migrations'
  },
  ssl: process.env.DATABASE_SSL !== 'false' ? {
    rejectUnauthorized: false
  } : false
});

async function runMigration() {
  console.log('üîÑ Running production database migration...\n');

  try {
    // Check current migration status
    console.log('üìã Current migration status:');
    const [completed, pending] = await knex.migrate.list();
    console.log(`   Completed: ${completed.length} migrations`);
    console.log(`   Pending: ${pending.length} migrations\n`);

    if (pending.length === 0) {
      console.log('‚úÖ Database is already up to date!');
      
      // Show variant columns
      console.log('\nüìä Checking variant columns in products table:');
      const columns = await knex('products').columnInfo();
      const variantColumns = Object.keys(columns).filter(c => 
        c.includes('variant') || c.includes('option') || c.includes('parent_product')
      );
      
      if (variantColumns.length > 0) {
        console.log('   Variant columns found:');
        variantColumns.forEach(col => {
          console.log(`   ‚úÖ ${col} (${columns[col].type})`);
        });
      } else {
        console.log('   ‚ùå No variant columns found!');
      }
      
      await knex.destroy();
      process.exit(0);
    }

    // Run pending migrations
    console.log('üöÄ Running migrations...');
    const [batch, migrations] = await knex.migrate.latest();
    
    console.log(`\n‚úÖ Migration successful!`);
    console.log(`   Batch: ${batch}`);
    console.log(`   Migrations run:`);
    migrations.forEach(m => console.log(`   - ${m}`));

    // Verify variant columns
    console.log('\nüìä Verifying variant columns in products table:');
    const columns = await knex('products').columnInfo();
    const variantColumns = [
      'parent_product_id',
      'variant_title', 
      'variant_position',
      'option1_name',
      'option1_value',
      'option2_name',
      'option2_value',
      'option3_name',
      'option3_value',
      'is_parent_product'
    ];

    let allPresent = true;
    variantColumns.forEach(col => {
      if (columns[col]) {
        console.log(`   ‚úÖ ${col} (${columns[col].type})`);
      } else {
        console.log(`   ‚ùå ${col} - MISSING!`);
        allPresent = false;
      }
    });

    if (allPresent) {
      console.log('\nüéâ All variant columns present!');
    } else {
      console.log('\n‚ö†Ô∏è  Some variant columns are missing!');
    }

    await knex.destroy();
    process.exit(0);

  } catch (error) {
    console.error('\n‚ùå Migration failed:', error.message);
    console.error(error);
    await knex.destroy();
    process.exit(1);
  }
}

// Verify DATABASE_URL is set
if (!process.env.DATABASE_URL && !process.env.PRODUCTION_DATABASE_URL) {
  console.error('‚ùå DATABASE_URL or PRODUCTION_DATABASE_URL environment variable is required!');
  console.error('\nUsage:');
  console.error('  DATABASE_URL="postgresql://user:pass@host:port/db" node scripts/run-production-migration.js');
  console.error('  or');
  console.error('  PRODUCTION_DATABASE_URL="postgresql://..." node scripts/run-production-migration.js');
  process.exit(1);
}

console.log(`üì° Connecting to database: ${(process.env.DATABASE_URL || process.env.PRODUCTION_DATABASE_URL).split('@')[1]}\n`);

runMigration();
